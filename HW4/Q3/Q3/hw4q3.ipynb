{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB0vv4pBcWu9"
   },
   "source": [
    "# Q3 Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GalZFbfhcWvA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8CbpTPx9rKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pkaundinya3\n"
     ]
    }
   ],
   "source": [
    "# Change to your GA Tech ID\n",
    "ga_id = 'pkaundinya3'\n",
    "# Requires a print() statement do not modify below print statement\n",
    "print(ga_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Z1gV3UlcWvD"
   },
   "source": [
    "# Q3.1 Data Import and Cleansing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VS44b2kcWvE"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Read in all the data. Replace the 'xxx' with the path to the data set. We've started this for you. \n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "data = pd.read_csv('pulsar_stars.csv')\n",
    "# -------------------------------\n",
    "\n",
    "# XXX\n",
    "# TODO: Separate out the x_data and y_data. We've started this for you.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "x_data = data.loc[:,['X1','X2','X3','X4','X5','X6','X7','X8']]\n",
    "y_data = data.loc[:,'y']\n",
    "# -------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xuEypbCqcWvG"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Split 70% of the data into training and 30% into test sets. Call them x_train, x_test, y_train and y_test.\n",
    "# Use the train_test_split method in sklearn with the parameter 'shuffle' set to true and the 'random_state' \n",
    "# set to 614.\n",
    "# \n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# -------------------------------\n",
    "x_train, x_test, y_train,y_test = train_test_split(x_data,y_data,shuffle=True,random_state=614)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q09V5Ux5cWvI"
   },
   "source": [
    "# Q3.2 Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnHXBF1UcWvJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a LinearRegression classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "lin_model = LinearRegression(n_jobs=-1)\n",
    "lin_model.fit(x_train,y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McSbfk9WcWvL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971615883185577\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "lin_pred_train = np.rint(lin_model.predict(x_train))\n",
    "print(accuracy_score(y_train,lin_pred_train))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgySbn7xcWvN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9678212290502793\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the testing set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "lin_pred_test = np.rint(lin_model.predict(x_test))\n",
    "print(accuracy_score(y_test,lin_pred_test))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbqnCyHAcWvP"
   },
   "source": [
    "# Q3.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTtIFJW7cWvQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prathik\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=614, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a RandomForestClassifier and train it.\n",
    "# Set 'random_state' to 614\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "rf_model = RandomForestClassifier(random_state = 614,n_jobs=-1)\n",
    "rf_model.fit(x_train,y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWeNJLzqcWvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9963495492810847\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "rf_pred_train = rf_model.predict(x_train)\n",
    "print(accuracy_score(y_train,rf_pred_train))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsMXeLyncWvU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9769832402234637\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "rf_pred_test = rf_model.predict(x_test)\n",
    "print(accuracy_score(y_test,rf_pred_test))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEkwb0M3cWvW"
   },
   "source": [
    "## Q3.3.1 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmjevLlPcWvW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35951752 0.06134451 0.27238298 0.10875699 0.07179917 0.04190842\n",
      " 0.05964191 0.02464849]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Determine the feature importance as evaluated by the Random Forest Classifier.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(rf_model.feature_importances_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XcRI7kUcWvY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 5 6 1 4 3 2 0]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Sort them in the descending order and print the feature numbers[0 to ...].\n",
    "#       Hint: There is a direct function available in sklearn to achieve this. Also checkout argsort() function in Python.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(np.argsort(rf_model.feature_importances_))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AlCc_E3cWva"
   },
   "source": [
    "## Q3.3.2 Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3fjpmWLcWvb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prathik\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   12.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=-1,\n",
       "                                              oob_score=False, random_state=614,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 8, 16], 'n_estimators': [4, 16, 256]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'n_estimators' and 'max_depth'.\n",
    "# 'n_estimators': [4, 16, 256]\n",
    "# 'max_depth': [2, 8, 16]\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "param_grid_rf = {'n_estimators':[4, 16, 256],'max_depth':[2, 8, 16]}\n",
    "hptune_rf = GridSearchCV(rf_model,param_grid_rf,n_jobs=-1,verbose=5)\n",
    "hptune_rf.fit(x_train,y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0OaHSCRcWvc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 16, 'n_estimators': 256}\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best params, using .best_params_\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(hptune_rf.best_params_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyXkkZr9cWve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980257766520152\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best score, using .best_score_.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(hptune_rf.best_score_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNeOPWIpcWvg"
   },
   "source": [
    "# Q3.4 Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CN3Wkw7zcWvh"
   },
   "source": [
    "## Q3.4.1 Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9msZXyImcWvh"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Pre-process the data to standardize it, otherwise the grid search will take much longer.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x_data)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqz1htxM9rLO"
   },
   "source": [
    "## Q3.4.2 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_nrOJdIcWvj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prathik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a SVC classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "svc_model = SVC(verbose=True)\n",
    "svc_model.fit(x_train,y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U40EOPEecWvl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9937420844818595\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "svc_pred_train = svc_model.predict(x_train)\n",
    "print(accuracy_score(y_train,svc_pred_train))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_jidMDvcWvm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9077094972067039\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "svc_pred_test = svc_model.predict(x_test)\n",
    "print(accuracy_score(y_test,svc_pred_test))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89N3JURqcWvp"
   },
   "source": [
    "## Q3.4.3 Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufWB_j_-cWvq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prathik\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:   57.9s remaining:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=True),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1.0], 'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'C' and 'kernel' (use rbf and linear).\n",
    "# 'kernel':('linear', 'rbf') \n",
    "# 'C':[0.01, 0.1, 1.0]\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "param_grid_svc = {'kernel':['linear', 'rbf'],'C':[0.01, 0.1, 1.0]}\n",
    "hptune_svc = GridSearchCV(svc_model,param_grid_svc,n_jobs=-1,verbose=5,return_train_score=True)\n",
    "hptune_svc.fit(x_train,y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYsFkceBcWvu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9799597705430977\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best score, using .best_score_.\n",
    "# Note: Set n_jobs=-1 and return_train_score=True\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(hptune_svc.best_score_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_i1BM7zQcWvw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798852715488341\n",
      "0.9769832402234637\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Calculate the training and test set accuracy values after hyperparameter tuning and standardization. \n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(hptune_svc.score(x_train,y_train))\n",
    "print(hptune_svc.score(x_test,y_test))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UzWph6Y9rLs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798852715488341\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "hptune_svc_pred_train = hptune_svc.predict(x_train)\n",
    "print(accuracy_score(y_train,hptune_svc_pred_train))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSQXwaDn9rLw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9769832402234637\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the test set) using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "hptune_svc_pred_test = hptune_svc.predict(x_test)\n",
    "print(accuracy_score(y_test,hptune_svc_pred_test))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Io4IVbup9rL1"
   },
   "source": [
    "## Q3.4.4 Cross Validation Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kVfAqsbcWv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5 2 5 1 4]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the rank test score for all hyperparameter values that you obtained in Q3.4.3. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(hptune_svc.cv_results_['rank_test_score'])\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UrUu1DXcWv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97638382 0.90918573 0.97891678 0.90918573 0.97995977 0.90978172]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the mean testing score for all of hyperparameter values that you obtained in Q3.4.3. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(hptune_svc.cv_results_['mean_test_score'])\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2qDYMjgcWv5"
   },
   "source": [
    "# Q3.5 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-C9BuGsqcWv5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
       "    svd_solver='full', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Perform dimensionality reduction of the data using PCA.\n",
    "#       Set parameters n_component to 8 and svd_solver to 'full'. Keep other parameters at their default value.\n",
    "# XXX\n",
    "\n",
    "# NOTE: Use the full x data set for this section 'x_data'\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# You should see an output here of PCA(copy=True....)\n",
    "pca = PCA(n_components=8, svd_solver='full')\n",
    "pca.fit(x_data)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZCJCtGhcWv7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.71053041e-01 7.81934383e-02 4.11562290e-02 6.15967691e-03\n",
      " 2.43717952e-03 9.58578490e-04 3.90570992e-05 2.79968662e-06]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get percentage of variance explained by each of the selected components\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(pca.explained_variance_ratio_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9nPDDyTcWv8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14430.28004546  4323.5214088   3136.68022725  1213.47665361\n",
      "   763.30168073   478.70316467    96.62788002    25.87063984]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the singular values corresponding to each of the selected components.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(pca.singular_values_)\n",
    "# -------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw4q3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
